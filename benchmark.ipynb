{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kwant\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import meanfi\n",
    "from meanfi.kwant_helper import utils\n",
    "from meanfi.tb.transforms import tb_to_kfunc\n",
    "from scipy.optimize import root\n",
    "from meanfi.solvers import cost_density\n",
    "\n",
    "s0 = np.identity(2)\n",
    "sx = np.array([[0, 1], [1, 0]])\n",
    "sy = np.array([[0, -1j], [1j, 0]])\n",
    "sz = np.diag([1, -1])\n",
    "\n",
    "# Create graphene lattice\n",
    "graphene = kwant.lattice.general(\n",
    "    [(1, 0), (1 / 2, np.sqrt(3) / 2)], [(0, 0), (0, 1 / np.sqrt(3))], norbs=2\n",
    ")\n",
    "a, b = graphene.sublattices\n",
    "\n",
    "# Create bulk system\n",
    "bulk_graphene = kwant.Builder(kwant.TranslationalSymmetry(*graphene.prim_vecs))\n",
    "# Set onsite energy to zero\n",
    "bulk_graphene[a.shape((lambda pos: True), (0, 0))] = 0 * s0\n",
    "bulk_graphene[b.shape((lambda pos: True), (0, 0))] = 0 * s0\n",
    "# Add hoppings between sublattices\n",
    "bulk_graphene[graphene.neighbors(1)] = s0\n",
    "\n",
    "def onsite_int(site, U):\n",
    "    return U * sx\n",
    "\n",
    "def nn_int(site1, site2, V):\n",
    "    return V * np.ones((2, 2))\n",
    "\n",
    "builder_int = utils.build_interacting_syst(\n",
    "    builder=bulk_graphene,\n",
    "    lattice=graphene,\n",
    "    func_onsite=onsite_int,\n",
    "    func_hop=nn_int,\n",
    "    max_neighbor=1\n",
    ")\n",
    "params = dict(U=2.32, V=0)\n",
    "h_int_temp = utils.builder_to_tb(builder_int, params)\n",
    "h_int = {(0,0) : h_int_temp[(0,0)]} # only keep onsite for efficiency\n",
    "h_0 = utils.builder_to_tb(bulk_graphene)\n",
    "\n",
    "filling = 2\n",
    "model = meanfi.Model(h_0, h_int, filling=filling, atol=1e-4, kT=1e-2)\n",
    "int_keys = frozenset(h_int)\n",
    "ndof = len(list(h_0.values())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "common_options = {\n",
    "    'tol': 1e-5,\n",
    "}\n",
    "\n",
    "method_options = {\n",
    "    'df-sane': {'maxfev' : max_iter},\n",
    "    'anderson':  {'jac_options' : {'M' : 1}, 'maxiter' : max_iter},\n",
    "    'broyden2': {'maxiter' : max_iter},\n",
    "    'hybr' : {'maxfev' : max_iter}\n",
    "    }\n",
    "\n",
    "# Define a range of random seeds for the experiments.\n",
    "seeds = [1, 11, 21]\n",
    "\n",
    "# A list to collect benchmarking results.\n",
    "benchmark_results = []\n",
    "\n",
    "# (Optional) A sample callback function to record convergence history.\n",
    "def record_history_callback(residual, iteration, history):\n",
    "    history.append((iteration, residual))\n",
    "    return history\n",
    "\n",
    "# Loop over each method and each seed.\n",
    "for method, unique_opts in method_options.items():\n",
    "    \n",
    "    # Merge common options with the unique options and the method itself.\n",
    "    optimizer_kwargs = {**common_options, 'method': method, 'options' : unique_opts}\n",
    "    \n",
    "    for seed in seeds:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Initialize the guess (example; adjust to your code)\n",
    "        mf_guess = meanfi.guess_tb(int_keys, ndof)\n",
    "        mu_guess = 0\n",
    "        \n",
    "        # Prepare a list to capture the convergence history (if supported by your solver).\n",
    "        history = []\n",
    "        \n",
    "        #\n",
    "        if method == 'hybr':\n",
    "            callback_fun = None\n",
    "        else:\n",
    "            callback_fun = lambda res, it: record_history_callback(res, it, history)\n",
    "\n",
    "        # Run the solver.\n",
    "        # Here, we assume that `meanfi.solver` supports a callback mechanism to log residuals.\n",
    "        # If not, you might need to modify the solver or wrap it to collect this info.\n",
    "        _, result = meanfi.solver(\n",
    "            model, \n",
    "            mf_guess, \n",
    "            mu_guess, \n",
    "            optimizer=root, \n",
    "            optimizer_kwargs=optimizer_kwargs, \n",
    "            debug=True, \n",
    "            factor=1, \n",
    "            optimizer_return=True,\n",
    "            callback=callback_fun\n",
    "        )\n",
    "\n",
    "        if method == 'hybr':\n",
    "            history = cost_density.history\n",
    "        \n",
    "        # Collect information from the solver result.\n",
    "        # Adjust attribute names (like `n_iter`) based on what your result object provides.\n",
    "        benchmark_results.append({\n",
    "            'method': method,\n",
    "            'seed': seed,\n",
    "            'success': result.success,\n",
    "            'iterations': getattr(result, 'n_iter', None),  # Replace 'n_iter' with actual attribute name if different\n",
    "            'message': result.message,\n",
    "            'history': history  # Contains tuples of (iteration, residual) if available\n",
    "        })\n",
    "        \n",
    "        # Optionally, print immediate feedback.\n",
    "        if result.success:\n",
    "            print(f\"[{method} | seed={seed}] Solver converged in {getattr(result, 'nfev', 'N/A')} iterations.\")\n",
    "        else:\n",
    "            print(f\"[{method} | seed={seed}] Solver did not converge: {result.message}\")\n",
    "\n",
    "# Convert collected results into a DataFrame for easier analysis.\n",
    "df_results = pd.DataFrame(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# log plot of residuals\n",
    "# in the same plot, for the same seed, compare the residuals of different methods in one plot, and the filling residuals in the other plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "for method in df_results['method'].unique():\n",
    "    for seed in df_results['seed'].unique():\n",
    "        history = next(row['history'] for _, row in df_results.iterrows() if row['method'] == method and row['seed'] == seed)\n",
    "        residuals = [np.linalg.norm(residual[:-1]) for residual, _ in history]\n",
    "        filling_residual = [residual[-1] for residual, _ in history]\n",
    "        ax[0].plot(np.abs(filling_residual), marker='o', label=f\"{method} (seed={seed})\")\n",
    "        ax[1].plot(residuals, marker='o', label=f\"{method} (seed={seed})\")\n",
    "\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_title('Filling Residuals Comparison')\n",
    "ax[0].set_xlabel('Methods')\n",
    "ax[0].set_ylabel('Filling Residuals')\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "\n",
    "# make this log scale\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_title('Residuals Comparison')\n",
    "ax[1].set_xlabel('Methods')\n",
    "ax[1].set_ylabel('Residuals')\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
